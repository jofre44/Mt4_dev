{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darwinex_ticks as dtw1\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from datetime import timedelta  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_list=list(pd.read_csv(\"C:/Users/Isabel Cristina/Desktop/Algo_trading_py/configs/pairs.txt\", header = None)[0])\n",
    "configs_info=pd.read_csv(\"C:/Users/Isabel Cristina/Desktop/Algo_trading_py/configs/configs.txt\", header = None, sep= \"=\", names=['Desc', 'Value'])\n",
    "\n",
    "user= configs_info[configs_info.Desc=='user'].Value.iloc[0]\n",
    "password= configs_info[configs_info.Desc=='password'].Value.iloc[0]\n",
    "host_name= configs_info[configs_info.Desc=='host_name'].Value.iloc[0]\n",
    "start_date= configs_info[configs_info.Desc=='start_date'].Value.iloc[0]\n",
    "end_date= configs_info[configs_info.Desc=='end_date'].Value.iloc[0]\n",
    "percentile= pd.to_numeric(configs_info[configs_info.Desc=='percentile'].Value.iloc[0])\n",
    "\n",
    "dwt = dtw1.DarwinexTicksConnection(dwx_ftp_user=user,\n",
    "                       dwx_ftp_pass=password,\n",
    "                       dwx_ftp_hostname=host_name,\n",
    "                       dwx_ftp_port=21)\n",
    "path = 'C:/Users/Isabel Cristina/Desktop/Algo_trading_py/data/historical_data/*.csv'\n",
    "csv_files = glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_end = date.today() - timedelta(days = 5)\n",
    "for pair in pairs_list:\n",
    "    \n",
    "    file = [s for s in csv_files if pair in s ]\n",
    "\n",
    "    if len(file) == 0:\n",
    "        print(\"\\n No previoius data downloaded\")\n",
    "        date_start = start_date\n",
    "    elif first_dwn_data:\n",
    "        date_start = start_date\n",
    "    else:\n",
    "        date_start = file[0].split(\"\\\\\")[-1].split(\"_\")[-1].split(\".\")[0]-timedelta(days = 1)\n",
    "\n",
    "    date_range = pd.date_range(date_start,date_end , freq='D').to_series()\n",
    "    \n",
    "    data_ohlc = pd.DataFrame()\n",
    "    \n",
    "    for date_ini in date_range:\n",
    "\n",
    "        date_end_period = pd.to_datetime(date_ini) + timedelta(hours = 23)\n",
    "\n",
    "        print(\"Dowloading data from Darwinex, date: {} \".format(date_ini))\n",
    "        try:\n",
    "            data = dwt.ticks_from_darwinex(pair, start=date_ini, end=date_end_period,  darwinex_time=True)\n",
    "        except:\n",
    "            print(\"Date with not data\")\n",
    "        data['Price'] = (data.Ask + data.Bid) / 2\n",
    "        data_ohlc_prev = data['Price'].resample('1Min').ohlc()\n",
    "        data_ohlc =data_ohlc.append(data_ohlc_prev)\n",
    "\n",
    "    data_ohlc.index = pd.to_datetime(data_ohlc.index.astype(str).map(lambda x: str(x)[:19]))\n",
    "    min_date = min(data_ohlc.index)\n",
    "    max_date = max(data_ohlc.index)\n",
    "\n",
    "    if len(file) == 0:\n",
    "        \n",
    "        data_total = data_ohlc\n",
    "        start_date_filter = min_date\n",
    "    else:\n",
    "        \n",
    "        # Date for filtering\n",
    "        start_date_filter = pd.to_datetime('2006-07-01')\n",
    "        \n",
    "        # Reading data from mt4\n",
    "        print(\"Reading csv\")\n",
    "        data_mt = pd.read_csv(file, header=None)\n",
    "\n",
    "        # Procesing data\n",
    "        data_mt.columns = [\"Date\", \"Hora\", \"open\", \"high\", \"low\", \"close\"]#, \"Vol\"]\n",
    "        data_mt['Time'] = pd.to_datetime(data_mt['Date'] + ' ' + data_mt['Hora'])\n",
    "        data_mt = data_mt[['Time', 'open', 'high', 'low', 'close']].set_index('Time')\n",
    "\n",
    "        # Setting time zone\n",
    "        data_mt = data_mt.loc[start_date_filter:min_date]\n",
    "\n",
    "        # Merging data\n",
    "        data_total = data_mt.append(data_ohlc).reset_index()\n",
    "    \n",
    "    \n",
    "    data_total['Date'] = data_total.Time.dt.strftime('%Y.%m.%d')\n",
    "    data_total['Hour'] = data_total.Time.dt.strftime('%H:%M')\n",
    "    data_total = data_total[['Date', 'Hour', 'open', 'high', 'low', 'close']]\n",
    "\n",
    "    # Saving csv data\n",
    "    print(\"Saving updated data...\")\n",
    "    data_total.to_csv(\"data\\{}_M1_from_{}_to_{}.csv\".format(pair, str(start_date_filter), str(max_date).split(sep=\" \")[0]), \n",
    "                                                                            header=False, index=False)\n",
    "    os.remove(\"data\\{}\".format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohlc#.iloc[701:750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files:\n",
    "    pair = file.split(\"\\\\\")[-1][0:6]\n",
    "    print(\"\\n--- CREATING DATA FOR FILE {}: {} ---\\n\".format(i, pair))\n",
    "\n",
    "    # Reading data from darwinex\n",
    "    print(\"Dowloading data from Darwinex from {} to {}\".format(start_date, end_date))\n",
    "    data = dwt.ticks_from_darwinex(pair, start=start_date, end=end_date, verbose = False)\n",
    "    data['Price'] = (data.Ask + data.Bid) / 2\n",
    "    data_ohlc = data['Price'].resample('1Min').ohlc()\n",
    "\n",
    "    # Date for filtering\n",
    "    start_date_filter = pd.to_datetime('2006-07-01').tz_localize('UTC')\n",
    "    min_date = min(data_ohlc.index)\n",
    "    # min_hour = data_ohlc.Hour[0]\n",
    "    max_date = max(data_ohlc.index)\n",
    "\n",
    "    # Reading data from mt4\n",
    "    print(\"Reading csv\")\n",
    "    data_mt = pd.read_csv(file, header=None)\n",
    "\n",
    "    # Procesing data\n",
    "    data_mt.columns = [\"Date\", \"Hora\", \"open\", \"high\", \"low\", \"close\"]#, \"Vol\"]\n",
    "    data_mt['Time'] = pd.to_datetime(data_mt['Date'] + ' ' + data_mt['Hora'])\n",
    "    data_mt = data_mt[['Time', 'open', 'high', 'low', 'close']].set_index('Time')\n",
    "\n",
    "    # Setting time zone\n",
    "    data_mt.index = data_mt.index.tz_localize('UTC')\n",
    "    data_mt.index = data_mt.index - pd.Timedelta(hours=2)\n",
    "    data_mt = data_mt.loc[start_date_filter:min_date]\n",
    "\n",
    "    # Merging data\n",
    "    data_total = data_mt.append(data_ohlc).reset_index()\n",
    "    data_total['Date'] = data_total.Time.dt.strftime('%Y.%m.%d')\n",
    "    data_total['Hour'] = data_total.Time.dt.strftime('%H:%M')\n",
    "    data_total = data_total[['Date', 'Hour', 'open', 'high', 'low', 'close']]\n",
    "\n",
    "    # Saving csv data\n",
    "    print(\"Saving updated data...\")\n",
    "    data_total.to_csv(\"data_updated\\{}_M1_from_2006-07-01_to_{}.csv\".format(pair, str(max_date).split(sep=\" \")[0]), \n",
    "                                                                            header=False, index=False)\n",
    "\n",
    "    i += 1\n",
    "    del data, data_ohlc, data_total, data_mt\n",
    "    gc.collect()\n",
    "print (\"\\n--- DONE ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
